{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae4525c0",
   "metadata": {},
   "source": [
    "\n",
    "# <p style=\"text-align:center\"> <font color='darkorange'>**CUNEF**</font>\n",
    "## <p style=\"text-align:center\"> **TFM - Análisis de sentimiento pólitico en Twitter**\n",
    "### <p style=\"text-align:center\"> **0. Selección de datos y preparación de variables**</strong><br />\n",
    "    \n",
    "<p style=\"text-align:left\">Pablo Mazariegos Reviriego - <font color='orange'>pablo.mazariegos@cunef.edu </font>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3644c68",
   "metadata": {},
   "source": [
    "En este proyecto de Trabajo Fin de Máster, realizaremos un análisis de sentimiento de los tweets hechos por los 5 candidatos políticos a la presidencia de Madrid durante el período de campaña política que abarcó desde el 12 hasta el 27 de mayo de 2023. Utilizaremos una base de datos recopilada manualmente que contiene los tweets de los candidatos. El objetivo principal de este proyecto es desarrollar modelos de aprendizaje automático que puedan clasificar los tweets según su sentimiento (positivo, negativo o neutral).\n",
    "\n",
    "El proyecto se organizará en diferentes cuadernos, cada uno enfocado en una etapa específica del proceso:\n",
    "\n",
    " 0. <font color='darkgreen'> **Selección de datos y preparación de variables**</font>\n",
    " 1. EDA\n",
    " 2. Word Cloud y Análisis de viralidad\n",
    " 3. Best Model and Explainability\n",
    "\n",
    "Este cuaderno se enfoca en el análisis de datos de los tweets de los candidatos políticos durante la campaña electoral de Madrid. Realizaremos un análisis exploratorio de los datos, utilizando técnicas de visualización y evaluando el sentimiento político expresado en los tweets. Además, emplearemos un modelo de sentimiento político previamente entrenado para clasificar los tweets en categorías de sentimiento. Compartiremos nuestros resultados a través de visualizaciones informativas y resumidas, lo que nos permitirá obtener una comprensión más profunda de las opiniones y actitudes de los usuarios durante la campaña política.\n",
    "\n",
    "  **INDICE:**\n",
    " \n",
    " - [Importación de Librerias](#0) \n",
    " - [Funciones utilizadas en este notebook](#1) \n",
    " - [Carga de datos](#2)\n",
    " - [Exploración de los datos](#3)\n",
    " - [Modelo de Sentimiento Pólitico](#4)\n",
    "\n",
    "  **Correlación:**\n",
    " - [Correlación de las variables](#5)\n",
    " - [Spearman](#5.1)\n",
    " - [Cramer's V](#5.2)\n",
    " - [Pearson](#5.3)\n",
    " \n",
    " \n",
    " - [Exportación de los datos](#9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0cb36a",
   "metadata": {},
   "source": [
    "##  <a name=\"0\"> Importación de Librerias</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed39133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from scipy.special import softmax\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39abcc70",
   "metadata": {},
   "source": [
    "##  <a name=\"1\">Funciones utilizadas en este notebook</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606aafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una función para preprocesar cada tweet\n",
    "def preprocess_tweet(tweet):\n",
    "    # Solo procesamos si el input es de tipo string\n",
    "    if isinstance(tweet, str):\n",
    "        tweet = tweet.lower()  # Convertimos el tweet a minúsculas\n",
    "      \n",
    "        tweet_words = []\n",
    "        # Recorremos cada palabra en el tweet\n",
    "        for word in tweet.split(' '):\n",
    "            # Si la palabra es una mención a un usuario, la reemplazamos por '@user'\n",
    "            if word.startswith('@') and len(word) > 1:\n",
    "                word = '@user'\n",
    "            # Si la palabra es un enlace, la reemplazamos por 'http'\n",
    "            elif word.startswith('http'):\n",
    "                word = \"http\"\n",
    "            # Añadimos la palabra a la lista de palabras del tweet\n",
    "            tweet_words.append(word)\n",
    "\n",
    "        # Devolvemos el tweet procesado\n",
    "        return \" \".join(tweet_words)\n",
    "    else:\n",
    "        # Si el input no es una string, devolvemos una string vacía\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae34200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una función para analizar el sentimiento de un tweet\n",
    "def analyze_sentiment(tweet):\n",
    "    # Codificamos el tweet para que pueda ser procesado por el modelo\n",
    "    encoded_tweet = tokenizer(tweet, return_tensors='pt')\n",
    "    # Obtenemos las puntuaciones de sentimiento del modelo\n",
    "    output = model(**encoded_tweet)\n",
    "    # Convertimos las puntuaciones en un array de numpy\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    # Convertimos las puntuaciones en probabilidades usando la función softmax\n",
    "    scores = softmax(scores)\n",
    "    # Devolvemos un diccionario que asocia cada etiqueta con su probabilidad\n",
    "    return dict(zip(labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46d4281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_matrix(dataset=None, metodo='spearman', size_figure=[10,8]):\n",
    "    if dataset is None:\n",
    "        print(u'\\nHace falta pasar argumentos a la función')\n",
    "        return 1\n",
    "    sns.set(style=\"white\")\n",
    "    corr = dataset.corr(method=metodo)\n",
    "    for i in range(corr.shape[0]):\n",
    "        corr.iloc[i, i] = 0\n",
    "    f, ax = plt.subplots(figsize=size_figure)\n",
    "    sns.heatmap(corr, annot=True, fmt=\".2f\", square=True, linewidths=.5, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e5c69be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramers_v(var1,var2):\n",
    "    \"\"\" \n",
    "    calculate Cramers V statistic for categorial-categorial association.\n",
    "    uses correction from Bergsma and Wicher,\n",
    "    Journal of the Korean Statistical Society 42 (2013): 323-328\n",
    "    \n",
    "    confusion_matrix: tabla creada con pd.crosstab()\n",
    "    \n",
    "    \"\"\"\n",
    "    crosstab =np.array(pd.crosstab(var1,var2, rownames=None, colnames=None))\n",
    "    chi2 = ss.chi2_contingency(crosstab)[0]\n",
    "    n = crosstab.sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = crosstab.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min((kcorr-1),(rcorr-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e160fe",
   "metadata": {},
   "source": [
    "##  <a name=\"2\"> Carga de datos</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "972ae083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARTIDO</th>\n",
       "      <th>CANDIDATO</th>\n",
       "      <th>NICK</th>\n",
       "      <th>FOLLOWERS</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>POST</th>\n",
       "      <th>VIDEO</th>\n",
       "      <th>FOTO</th>\n",
       "      <th>REPOST</th>\n",
       "      <th>RETWEET</th>\n",
       "      <th>WHO</th>\n",
       "      <th>COMMENTS</th>\n",
       "      <th>SHARED</th>\n",
       "      <th>LIKES</th>\n",
       "      <th>VIEWED</th>\n",
       "      <th>VOTOS</th>\n",
       "      <th>PORCENTAJE</th>\n",
       "      <th>ESCAÑOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PP</td>\n",
       "      <td>Isabel Díaz Ayuso</td>\n",
       "      <td>@IdiazAyuso</td>\n",
       "      <td>912100</td>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>Comenzamos la campaña, una vez más, junto a la...</td>\n",
       "      <td>SI</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198</td>\n",
       "      <td>261</td>\n",
       "      <td>1260</td>\n",
       "      <td>58700</td>\n",
       "      <td>1586985</td>\n",
       "      <td>0.4734</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PP</td>\n",
       "      <td>Isabel Díaz Ayuso</td>\n",
       "      <td>@IdiazAyuso</td>\n",
       "      <td>912100</td>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>Madrid es la región del Espíritu de Ermua, la ...</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>561</td>\n",
       "      <td>2127</td>\n",
       "      <td>101600</td>\n",
       "      <td>1586985</td>\n",
       "      <td>0.4734</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PP</td>\n",
       "      <td>Isabel Díaz Ayuso</td>\n",
       "      <td>@IdiazAyuso</td>\n",
       "      <td>912100</td>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>Majadahonda con ganas de Libertad, familia, un...</td>\n",
       "      <td>NO</td>\n",
       "      <td>SI</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>213</td>\n",
       "      <td>1042</td>\n",
       "      <td>59700</td>\n",
       "      <td>1586985</td>\n",
       "      <td>0.4734</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PP</td>\n",
       "      <td>Isabel Díaz Ayuso</td>\n",
       "      <td>@IdiazAyuso</td>\n",
       "      <td>912100</td>\n",
       "      <td>2023-05-13</td>\n",
       "      <td>❤️❤️</td>\n",
       "      <td>NO</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>NO</td>\n",
       "      <td>@cayetanaAT\\n</td>\n",
       "      <td>155</td>\n",
       "      <td>343</td>\n",
       "      <td>2958</td>\n",
       "      <td>159100</td>\n",
       "      <td>1586985</td>\n",
       "      <td>0.4734</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PP</td>\n",
       "      <td>Isabel Díaz Ayuso</td>\n",
       "      <td>@IdiazAyuso</td>\n",
       "      <td>912100</td>\n",
       "      <td>2023-05-13</td>\n",
       "      <td>Presidente: líbranos del mal.</td>\n",
       "      <td>NO</td>\n",
       "      <td>SI</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>893</td>\n",
       "      <td>549</td>\n",
       "      <td>2592</td>\n",
       "      <td>330800</td>\n",
       "      <td>1586985</td>\n",
       "      <td>0.4734</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PARTIDO          CANDIDATO          NICK  FOLLOWERS      FECHA  \\\n",
       "0      PP  Isabel Díaz Ayuso   @IdiazAyuso     912100 2023-05-12   \n",
       "1      PP  Isabel Díaz Ayuso   @IdiazAyuso     912100 2023-05-12   \n",
       "2      PP  Isabel Díaz Ayuso   @IdiazAyuso     912100 2023-05-12   \n",
       "3      PP  Isabel Díaz Ayuso   @IdiazAyuso     912100 2023-05-13   \n",
       "4      PP  Isabel Díaz Ayuso   @IdiazAyuso     912100 2023-05-13   \n",
       "\n",
       "                                                POST VIDEO FOTO REPOST  \\\n",
       "0  Comenzamos la campaña, una vez más, junto a la...    SI   NO     NO   \n",
       "1  Madrid es la región del Espíritu de Ermua, la ...    NO   NO     NO   \n",
       "2  Majadahonda con ganas de Libertad, familia, un...    NO   SI     NO   \n",
       "3                                               ❤️❤️    NO   SI     SI   \n",
       "4                      Presidente: líbranos del mal.    NO   SI     NO   \n",
       "\n",
       "  RETWEET             WHO  COMMENTS  SHARED  LIKES  VIEWED    VOTOS  \\\n",
       "0      NO             NaN       198     261   1260   58700  1586985   \n",
       "1      NO             NaN       550     561   2127  101600  1586985   \n",
       "2      NO             NaN       140     213   1042   59700  1586985   \n",
       "3      NO   @cayetanaAT\\n       155     343   2958  159100  1586985   \n",
       "4      NO             NaN       893     549   2592  330800  1586985   \n",
       "\n",
       "   PORCENTAJE  ESCAÑOS  \n",
       "0      0.4734       71  \n",
       "1      0.4734       70  \n",
       "2      0.4734       70  \n",
       "3      0.4734       70  \n",
       "4      0.4734       70  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/raw/tweets_12-27Mayo.xlsx', usecols=lambda x: x != 'Nº')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6777ced1",
   "metadata": {},
   "source": [
    "##  <a name=\"3\"> Exploración de los datos</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043e2fb1",
   "metadata": {},
   "source": [
    "El método info() proporciona información esencial sobre tu DataFrame. Este resumen incluye:\n",
    "\n",
    "1. El número total de filas y la gama de índices.\n",
    "2. El número total de columnas.\n",
    "3. El nombre de cada columna, la cantidad de valores no nulos que tiene y su tipo de datos.\n",
    "4. La cantidad de memoria que utiliza el DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0bfbc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of rows in the data is:   773\n",
      "Count of columns in the data is:   18\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 773 entries, 0 to 772\n",
      "Data columns (total 18 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   PARTIDO     773 non-null    object        \n",
      " 1   CANDIDATO   773 non-null    object        \n",
      " 2   NICK        773 non-null    object        \n",
      " 3   FOLLOWERS   773 non-null    int64         \n",
      " 4   FECHA       773 non-null    datetime64[ns]\n",
      " 5   POST        771 non-null    object        \n",
      " 6   VIDEO       773 non-null    object        \n",
      " 7   FOTO        773 non-null    object        \n",
      " 8   REPOST      773 non-null    object        \n",
      " 9   RETWEET     773 non-null    object        \n",
      " 10  WHO         431 non-null    object        \n",
      " 11  COMMENTS    773 non-null    int64         \n",
      " 12  SHARED      773 non-null    int64         \n",
      " 13  LIKES       773 non-null    int64         \n",
      " 14  VIEWED      773 non-null    int64         \n",
      " 15  VOTOS       773 non-null    int64         \n",
      " 16  PORCENTAJE  773 non-null    float64       \n",
      " 17  ESCAÑOS     773 non-null    int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(7), object(9)\n",
      "memory usage: 108.8+ KB\n"
     ]
    }
   ],
   "source": [
    "print('Count of rows in the data is:  ', len(df))\n",
    "print('Count of columns in the data is:  ', len(df.columns))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dad2ddf",
   "metadata": {},
   "source": [
    "Comprobamos el total de nulos que hay en cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "207ebcf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PARTIDO         0\n",
       "CANDIDATO       0\n",
       "NICK            0\n",
       "FOLLOWERS       0\n",
       "FECHA           0\n",
       "POST            2\n",
       "VIDEO           0\n",
       "FOTO            0\n",
       "REPOST          0\n",
       "RETWEET         0\n",
       "WHO           342\n",
       "COMMENTS        0\n",
       "SHARED          0\n",
       "LIKES           0\n",
       "VIEWED          0\n",
       "VOTOS           0\n",
       "PORCENTAJE      0\n",
       "ESCAÑOS         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cd7b69",
   "metadata": {},
   "source": [
    "Se modifican los \"NO\" por False y \"SI\" por True de las columnas VIDEO, FOTO, REPOTS, RETWEET y WHO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "994bc582",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({'VIDEO': {'NO': False, 'SI': True},\n",
    "            'FOTO': {'NO': False, 'SI': True},\n",
    "            'REPOST': {'NO': False, 'SI': True},\n",
    "            'RETWEET': {'NO': False, 'SI': True},\n",
    "            'WHO': {np.nan: False}}, inplace=True)\n",
    "\n",
    "df['COMMENTS vs VIEWED'] = df['COMMENTS'] / df['VIEWED']\n",
    "df['SHARED vs VIEWED'] = df['SHARED'] / df['VIEWED']\n",
    "df['LIKES vs VIEWED'] = df['LIKES'] / df['VIEWED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8d76807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARTIDO</th>\n",
       "      <th>CANDIDATO</th>\n",
       "      <th>NICK</th>\n",
       "      <th>FOLLOWERS</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>POST</th>\n",
       "      <th>VIDEO</th>\n",
       "      <th>FOTO</th>\n",
       "      <th>REPOST</th>\n",
       "      <th>RETWEET</th>\n",
       "      <th>...</th>\n",
       "      <th>COMMENTS</th>\n",
       "      <th>SHARED</th>\n",
       "      <th>LIKES</th>\n",
       "      <th>VIEWED</th>\n",
       "      <th>VOTOS</th>\n",
       "      <th>PORCENTAJE</th>\n",
       "      <th>ESCAÑOS</th>\n",
       "      <th>COMMENTS vs VIEWED</th>\n",
       "      <th>SHARED vs VIEWED</th>\n",
       "      <th>LIKES vs VIEWED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PP</td>\n",
       "      <td>Isabel Díaz Ayuso</td>\n",
       "      <td>@IdiazAyuso</td>\n",
       "      <td>912100</td>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>Comenzamos la campaña, una vez más, junto a la...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>198</td>\n",
       "      <td>261</td>\n",
       "      <td>1260</td>\n",
       "      <td>58700</td>\n",
       "      <td>1586985</td>\n",
       "      <td>0.4734</td>\n",
       "      <td>71</td>\n",
       "      <td>0.003373</td>\n",
       "      <td>0.004446</td>\n",
       "      <td>0.021465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PP</td>\n",
       "      <td>Isabel Díaz Ayuso</td>\n",
       "      <td>@IdiazAyuso</td>\n",
       "      <td>912100</td>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>Madrid es la región del Espíritu de Ermua, la ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>550</td>\n",
       "      <td>561</td>\n",
       "      <td>2127</td>\n",
       "      <td>101600</td>\n",
       "      <td>1586985</td>\n",
       "      <td>0.4734</td>\n",
       "      <td>70</td>\n",
       "      <td>0.005413</td>\n",
       "      <td>0.005522</td>\n",
       "      <td>0.020935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PP</td>\n",
       "      <td>Isabel Díaz Ayuso</td>\n",
       "      <td>@IdiazAyuso</td>\n",
       "      <td>912100</td>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>Majadahonda con ganas de Libertad, familia, un...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>140</td>\n",
       "      <td>213</td>\n",
       "      <td>1042</td>\n",
       "      <td>59700</td>\n",
       "      <td>1586985</td>\n",
       "      <td>0.4734</td>\n",
       "      <td>70</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.003568</td>\n",
       "      <td>0.017454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PP</td>\n",
       "      <td>Isabel Díaz Ayuso</td>\n",
       "      <td>@IdiazAyuso</td>\n",
       "      <td>912100</td>\n",
       "      <td>2023-05-13</td>\n",
       "      <td>❤️❤️</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>155</td>\n",
       "      <td>343</td>\n",
       "      <td>2958</td>\n",
       "      <td>159100</td>\n",
       "      <td>1586985</td>\n",
       "      <td>0.4734</td>\n",
       "      <td>70</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>0.018592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PP</td>\n",
       "      <td>Isabel Díaz Ayuso</td>\n",
       "      <td>@IdiazAyuso</td>\n",
       "      <td>912100</td>\n",
       "      <td>2023-05-13</td>\n",
       "      <td>Presidente: líbranos del mal.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>893</td>\n",
       "      <td>549</td>\n",
       "      <td>2592</td>\n",
       "      <td>330800</td>\n",
       "      <td>1586985</td>\n",
       "      <td>0.4734</td>\n",
       "      <td>70</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.007836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PARTIDO          CANDIDATO          NICK  FOLLOWERS      FECHA  \\\n",
       "0      PP  Isabel Díaz Ayuso   @IdiazAyuso     912100 2023-05-12   \n",
       "1      PP  Isabel Díaz Ayuso   @IdiazAyuso     912100 2023-05-12   \n",
       "2      PP  Isabel Díaz Ayuso   @IdiazAyuso     912100 2023-05-12   \n",
       "3      PP  Isabel Díaz Ayuso   @IdiazAyuso     912100 2023-05-13   \n",
       "4      PP  Isabel Díaz Ayuso   @IdiazAyuso     912100 2023-05-13   \n",
       "\n",
       "                                                POST  VIDEO   FOTO  REPOST  \\\n",
       "0  Comenzamos la campaña, una vez más, junto a la...   True  False   False   \n",
       "1  Madrid es la región del Espíritu de Ermua, la ...  False  False   False   \n",
       "2  Majadahonda con ganas de Libertad, familia, un...  False   True   False   \n",
       "3                                               ❤️❤️  False   True    True   \n",
       "4                      Presidente: líbranos del mal.  False   True   False   \n",
       "\n",
       "   RETWEET  ... COMMENTS  SHARED  LIKES  VIEWED    VOTOS  PORCENTAJE  ESCAÑOS  \\\n",
       "0    False  ...      198     261   1260   58700  1586985      0.4734       71   \n",
       "1    False  ...      550     561   2127  101600  1586985      0.4734       70   \n",
       "2    False  ...      140     213   1042   59700  1586985      0.4734       70   \n",
       "3    False  ...      155     343   2958  159100  1586985      0.4734       70   \n",
       "4    False  ...      893     549   2592  330800  1586985      0.4734       70   \n",
       "\n",
       "   COMMENTS vs VIEWED  SHARED vs VIEWED  LIKES vs VIEWED  \n",
       "0            0.003373          0.004446         0.021465  \n",
       "1            0.005413          0.005522         0.020935  \n",
       "2            0.002345          0.003568         0.017454  \n",
       "3            0.000974          0.002156         0.018592  \n",
       "4            0.002700          0.001660         0.007836  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b6146b",
   "metadata": {},
   "source": [
    "Volvemos a comprobar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aec53325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of rows in the data is:   773\n",
      "Count of columns in the data is:   21\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 773 entries, 0 to 772\n",
      "Data columns (total 21 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   PARTIDO             773 non-null    object        \n",
      " 1   CANDIDATO           773 non-null    object        \n",
      " 2   NICK                773 non-null    object        \n",
      " 3   FOLLOWERS           773 non-null    int64         \n",
      " 4   FECHA               773 non-null    datetime64[ns]\n",
      " 5   POST                771 non-null    object        \n",
      " 6   VIDEO               773 non-null    bool          \n",
      " 7   FOTO                773 non-null    bool          \n",
      " 8   REPOST              773 non-null    bool          \n",
      " 9   RETWEET             773 non-null    bool          \n",
      " 10  WHO                 773 non-null    object        \n",
      " 11  COMMENTS            773 non-null    int64         \n",
      " 12  SHARED              773 non-null    int64         \n",
      " 13  LIKES               773 non-null    int64         \n",
      " 14  VIEWED              773 non-null    int64         \n",
      " 15  VOTOS               773 non-null    int64         \n",
      " 16  PORCENTAJE          773 non-null    float64       \n",
      " 17  ESCAÑOS             773 non-null    int64         \n",
      " 18  COMMENTS vs VIEWED  773 non-null    float64       \n",
      " 19  SHARED vs VIEWED    773 non-null    float64       \n",
      " 20  LIKES vs VIEWED     773 non-null    float64       \n",
      "dtypes: bool(4), datetime64[ns](1), float64(4), int64(7), object(5)\n",
      "memory usage: 105.8+ KB\n"
     ]
    }
   ],
   "source": [
    "print('Count of rows in the data is:  ', len(df))\n",
    "print('Count of columns in the data is:  ', len(df.columns))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf5df140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PARTIDO               0\n",
       "CANDIDATO             0\n",
       "NICK                  0\n",
       "FOLLOWERS             0\n",
       "FECHA                 0\n",
       "POST                  2\n",
       "VIDEO                 0\n",
       "FOTO                  0\n",
       "REPOST                0\n",
       "RETWEET               0\n",
       "WHO                   0\n",
       "COMMENTS              0\n",
       "SHARED                0\n",
       "LIKES                 0\n",
       "VIEWED                0\n",
       "VOTOS                 0\n",
       "PORCENTAJE            0\n",
       "ESCAÑOS               0\n",
       "COMMENTS vs VIEWED    0\n",
       "SHARED vs VIEWED      0\n",
       "LIKES vs VIEWED       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2b1a08",
   "metadata": {},
   "source": [
    "##  <a name=\"4\">Modelo de Sentimiento Pólitico</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3a0701",
   "metadata": {},
   "source": [
    "Para añadir el sentimiento de los Post, utilizo un modelo ya entrenado \"cardiffnlp/xlm-twitter-politics-sentiment\".\n",
    "\n",
    "Esta es una \"extensión\" del modelo multilingüe twitter-xlm-roberta-base-sentiment (modelo, artículo original) con un enfoque en el sentimiento de los tweets de los políticos. El ajuste fino del sentimiento original se realizó en 8 idiomas (Ar, En, Fr, De, Hi, It, Sp, Pt), pero se realizó un entrenamiento adicional utilizando tweets de Miembros del Parlamento del Reino Unido (inglés), España (español) y Grecia (griego). Este modelo cuenta con datos hasta el año 2021.\n",
    "\n",
    "**Se puede encontrar aqui:** https://huggingface.co/cardiffnlp/xlm-twitter-politics-sentiment\n",
    "\n",
    "**Modelo base Roberta** \n",
    "\n",
    "Este es un modelo multilingüe XLM-roBERTa-base entrenado en aproximadamente 198 millones de tweets y afinado para el análisis de sentimientos. El ajuste fino del sentimiento se realizó en 8 idiomas (Ar, En, Fr, De, Hi, It, Sp, Pt), pero puede utilizarse para más idiomas (ver el artículo para más detalles). Este modelo ha sido entrenado con datos hasta el año 2020.\n",
    "\n",
    "**Se puede encontrar aqui:** https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71a6a12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el nombre del modelo pre-entrenado que vamos a utilizar\n",
    "MODEL = \"cardiffnlp/xlm-twitter-politics-sentiment\"\n",
    "\n",
    "# Cargamos el modelo para la clasificación de secuencias \n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "# Cargamos el tokenizador asociado a este modelo\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aea7b3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos la columna 'POST' del DataFrame original para trabajar con ella\n",
    "df_post = df['POST']\n",
    "\n",
    "# Definimos las etiquetas que usará el modelo para la clasificación\n",
    "labels = ['Negative', 'Neutral', 'Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23abdbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos la función de preprocesamiento a cada tweet\n",
    "df_post['processed_text'] = df_post.apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fcaffb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Aplicamos la función de análisis de sentimiento a cada tweet procesado\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_post[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_post\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprocessed_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43manalyze_sentiment\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfm\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfm\\lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfm\\lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfm\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m, in \u001b[0;36manalyze_sentiment\u001b[1;34m(tweet)\u001b[0m\n\u001b[0;32m      4\u001b[0m encoded_tweet \u001b[38;5;241m=\u001b[39m tokenizer(tweet, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Obtenemos las puntuaciones de sentimiento del modelo\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m output \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoded_tweet)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Convertimos las puntuaciones en un array de numpy\u001b[39;00m\n\u001b[0;32m      8\u001b[0m scores \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfm\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:1226\u001b[0m, in \u001b[0;36mXLMRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1223\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1226\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1232\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1233\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1234\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1236\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1237\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1238\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfm\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:854\u001b[0m, in \u001b[0;36mXLMRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    845\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    847\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m    848\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    849\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    852\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    853\u001b[0m )\n\u001b[1;32m--> 854\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    867\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfm\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:528\u001b[0m, in \u001b[0;36mXLMRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    519\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[0;32m    520\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    521\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    525\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    526\u001b[0m     )\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 528\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    538\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfm\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:412\u001b[0m, in \u001b[0;36mXLMRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    402\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    409\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    411\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 412\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfm\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:339\u001b[0m, in \u001b[0;36mXLMRobertaAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    331\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    337\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    338\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 339\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    349\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfm\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:219\u001b[0m, in \u001b[0;36mXLMRobertaSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m     key_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey(hidden_states))\n\u001b[1;32m--> 219\u001b[0m     value_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    221\u001b[0m query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(mixed_query_layer)\n\u001b[0;32m    223\u001b[0m use_cache \u001b[38;5;241m=\u001b[39m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfm\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Aplicamos la función de análisis de sentimiento a cada tweet procesado\n",
    "df_post['sentiment_analysis'] = df_post['processed_text'].apply(analyze_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ee1562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí estamos tomando la columna 'sentiment_analysis' del DataFrame df_post,\n",
    "# que contiene diccionarios, y la estamos convirtiendo en un DataFrame llamado\n",
    "# 'sentimiento_df'. Cada clave en los diccionarios se convierte en una columna en el\n",
    "# nuevo DataFrame. Esto se logra con el método apply(pd.Series).\n",
    "sentimiento_df = df_post['sentiment_analysis'].apply(pd.Series)\n",
    "\n",
    "# Aquí añadimos una nueva columna llamada 'sentimiento' al DataFrame sentimiento_df.\n",
    "# Para cada fila, el valor de esta nueva columna se determina usando el método\n",
    "# idxmax(axis=1). Este método devuelve el nombre de la columna que tiene el valor\n",
    "# más alto en esa fila. En otras palabras, estamos seleccionando el sentimiento\n",
    "# (Negative, Neutral, Positive) que tiene la probabilidad más alta de acuerdo con\n",
    "# el análisis de sentimientos realizado anteriormente.\n",
    "sentimiento_df['sentimiento'] = sentimiento_df.idxmax(axis=1)\n",
    "\n",
    "# Finalmente, mostramos las primeras filas del DataFrame para verificar que todo se haya\n",
    "# realizado correctamente.\n",
    "sentimiento_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725f9457",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, sentimiento_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796ba173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reorganización de las columnas\n",
    "column_order = ['PARTIDO', 'CANDIDATO', 'NICK', 'FOLLOWERS', 'FECHA', 'POST', 'sentimiento', 'Negative', 'Neutral', 'Positive', 'VIDEO', 'FOTO', 'REPOST', 'RETWEET', 'VIEWED',\n",
    "                'COMMENTS', 'COMMENTS vs VIEWED', 'SHARED', 'SHARED vs VIEWED', 'LIKES', 'LIKES vs VIEWED', 'VOTOS',\n",
    "                'PORCENTAJE', 'ESCAÑOS']\n",
    "\n",
    "df = df.reindex(columns=column_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7e6f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir los nombres de las columnas a minúsculas\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738938e3",
   "metadata": {},
   "source": [
    "Última visualización del data Frame antes de su exportación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb731c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6ccce2",
   "metadata": {},
   "source": [
    "# **Correlación**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10302706",
   "metadata": {},
   "source": [
    " ##  <a name=\"5\"> Correlación de las variables</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522ae1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))  # Tamaño personalizado en pulgadas (ancho, alto)\n",
    "correlation = df.corr()\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741d6248",
   "metadata": {},
   "source": [
    "## <a name=\"5.1\">Spearman</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5042a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spearman = df[['partido', 'candidato', 'nick', 'followers', 'fecha',\n",
    "       'post', 'sentimiento', 'negative', 'neutral', 'positive', 'video',\n",
    "       'foto', 'repost', 'retweet', 'viewed', 'comments', 'comments vs viewed',\n",
    "       'shared', 'shared vs viewed', 'likes', 'likes vs viewed', 'votos',\n",
    "       'porcentaje', 'escaños']]\n",
    "df_spearman.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0fb1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_corr_matrix(dataset = df_spearman, size_figure = [10,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02aed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman = df_spearman.corr(method = 'spearman')\n",
    "print(spearman)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c651a40",
   "metadata": {},
   "source": [
    "## <a name=\"5.2\">Cramer's V</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769d86f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categorical_variables = df[['partido', 'candidato', 'nick', 'sentimiento', 'video',\n",
    "                                               'foto', 'repost', 'retweet']]\n",
    "\n",
    "df_categorical_variables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04524862",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for var1 in df_categorical_variables :\n",
    "  col = []\n",
    "  for var2 in df_categorical_variables :\n",
    "    cramers = cramers_v(df_categorical_variables[var1], df_categorical_variables[var2]) # Cramer's V test\n",
    "    col.append(round(cramers,2)) # Keeping of the rounded value of the Cramer's V  \n",
    "  rows.append(col)\n",
    "  \n",
    "cramers_results = np.array(rows)\n",
    "df_vcramer = pd.DataFrame(cramers_results, columns = df_categorical_variables .columns,\n",
    "                          index = df_categorical_variables .columns)\n",
    "\n",
    "sns.heatmap(df_vcramer, vmin=0, vmax=1, square=True, annot=True, linewidths=.5, cmap='coolwarm', fmt=\".2f\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc9bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vcramer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5c4a3e",
   "metadata": {},
   "source": [
    "##  <a name=\"5.3\">Pearson</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c8e31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_continous_vairables = df[['followers', 'negative', 'neutral', 'positive', 'viewed', 'comments', 'comments vs viewed',\n",
    "       'shared', 'shared vs viewed', 'likes', 'likes vs viewed', 'votos',\n",
    "       'porcentaje', 'escaños']]\n",
    "df_continous_vairables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfab1c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_corr_matrix(dataset = df_continous_vairables,\n",
    "                metodo = 'pearson', size_figure = [10,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ff0866",
   "metadata": {},
   "source": [
    "##  <a name=\"9\"> Exportación de los datos</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7036cc",
   "metadata": {},
   "source": [
    "Seexportan los datos como \"df_sentimiento\" y en la carpeta de preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d39c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/processed/df_sentimiento.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "tfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
