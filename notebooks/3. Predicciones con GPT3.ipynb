{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beaf4291",
   "metadata": {},
   "source": [
    "\n",
    "# <p style=\"text-align:center\"> <font color='darkorange'>**CUNEF**</font>\n",
    "## <p style=\"text-align:center\"> **TFM - Análisis de sentimiento pólitico en Twitter**\n",
    "### <p style=\"text-align:center\"> **3. Predicciones con GPT3**</strong><br />\n",
    "    \n",
    "<p style=\"text-align:left\">Pablo Mazariegos Reviriego - <font color='orange'>pablo.mazariegos@cunef.edu </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0154a84",
   "metadata": {},
   "source": [
    "En este proyecto de Trabajo Fin de Máster, realizaremos un análisis de sentimiento de los tweets hechos por los 5 candidatos políticos a la presidencia de Madrid durante el período de campaña política que abarcó desde el 12 hasta el 27 de mayo de 2023. Utilizaremos una base de datos recopilada manualmente que contiene los tweets de los candidatos. El objetivo principal de este proyecto es desarrollar modelos de aprendizaje automático que puedan clasificar los tweets según su sentimiento (positivo, negativo o neutral).\n",
    "\n",
    "El proyecto se organizará en diferentes cuadernos, cada uno enfocado en una etapa específica del proceso:\n",
    "\n",
    " 1. EDA y Selección/Preparación de variables\n",
    " 2. Word Cloud y Análisis de viralidad\n",
    " 3. <font color='darkgreen'> **Predicciones con GPT3**</font>\n",
    " 4. Otros Modelos\n",
    "\n",
    "Este cuaderno se enfoca \n",
    "\n",
    "  **INDICE:**\n",
    " \n",
    " - [Importación de Librerias](#0) \n",
    " - [Funciones utilizadas en este notebook](#1) \n",
    " - [Carga de datos](#2)\n",
    " - [Creación de Json de los datos](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a4f19",
   "metadata": {},
   "source": [
    "##  <a name=\"0\"> Importación de Librerias</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a75a4b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'g' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mg\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'g' is not defined"
     ]
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e5a899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "import openai\n",
    "from getpass import getpass\n",
    "import unidecode\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb5e770",
   "metadata": {},
   "source": [
    "##  <a name=\"2\"> Carga de datos</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f422e839",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY_OPENAI = getpass('Introduce tu API_KEY de Open AI:')\n",
    "\n",
    "openai.api_key = API_KEY_OPENAI\n",
    "os.environ['OPENAI_API_KEY'] = API_KEY_OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ed6182",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/processed/df_sentimiento_final.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98502338",
   "metadata": {},
   "source": [
    "##  <a name=\"3\"> Creación de Json de los datos</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9855b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un nuevo data frame con las columnas que necesitas\n",
    "new_df = df[['post_clean', 'partido']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201fae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a1304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['partido'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da22451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtén un DataFrame que contiene solo las filas duplicadas\n",
    "duplicated_rows = new_df[new_df.duplicated()]\n",
    "\n",
    "# Muestra el valor completo de la columna \"post_clean\" de las filas duplicadas\n",
    "for index, row in duplicated_rows.iterrows():\n",
    "    print(row['post_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebe4956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtén un DataFrame que contiene solo las filas duplicadas\n",
    "duplicated_rows = new_df[new_df.duplicated()]\n",
    "\n",
    "# Muestra las filas duplicadas\n",
    "print(duplicated_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0622450",
   "metadata": {},
   "source": [
    "## Guardamos los tweets y partido en un Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23a0f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una lista vacía para almacenar los nuevos datos\n",
    "data = []\n",
    "\n",
    "# Itera sobre cada fila del nuevo data frame\n",
    "for index, row in new_df.iterrows():\n",
    "    # Crea un diccionario con el formato que necesitas\n",
    "    entry = {\"prompt\": row['post_clean'], \"completion\": row['partido']}\n",
    "    # Añade el diccionario a la lista\n",
    "    data.append(entry)\n",
    "\n",
    "# Finalmente, escribe los datos en un archivo JSON\n",
    "with open('formatted_tweets_politicos.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18a1b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar la existencia del archivo JSON\n",
    "file_path = 'formatted_tweets_politicos.json'\n",
    "if os.path.exists(file_path):\n",
    "    print(\"El archivo JSON existe.\")\n",
    "else:\n",
    "    print(\"El archivo JSON no existe.\")\n",
    "\n",
    "# Leer el contenido del archivo JSON\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "# Verificar si el archivo JSON está vacío\n",
    "if len(json_data) > 0:\n",
    "    print(\"El archivo JSON no está vacío.\")\n",
    "else:\n",
    "    print(\"El archivo JSON está vacío.\")\n",
    "\n",
    "# Imprimir algunos datos del archivo JSON\n",
    "print(\"Primeros 5 registros del archivo JSON:\")\n",
    "for entry in json_data[:5]:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b72b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!openai tools fine_tunes.prepare_data -f formatted_tweets_politicos.json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832a892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!openai api fine_tunes.create -t \"formatted_tweets_politicos_train.jsonl\" -v \"formatted_tweets_politicos_valid.jsonl\" -m text-davinci-003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1213e987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a4e4d0a",
   "metadata": {},
   "source": [
    "## Guardamos los tweets y sentimiento en un Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eacb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un nuevo data frame con las columnas que necesitas\n",
    "new_df = df[['post_clean', 'sentimiento']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057959b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una lista vacía para almacenar los nuevos datos\n",
    "data = []\n",
    "\n",
    "# Itera sobre cada fila del nuevo data frame\n",
    "for index, row in new_df.iterrows():\n",
    "    # Crea un diccionario con el formato que necesitas\n",
    "    entry = {\"prompt\": row['post_clean'], \"completion\": row['sentimiento']}\n",
    "    # Añade el diccionario a la lista\n",
    "    data.append(entry)\n",
    "\n",
    "# Finalmente, escribe los datos en un archivo JSON\n",
    "with open('formatted_tweets_sentimiento.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f16cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!openai api fine_tunes.create -t \"formatted_tweets_sentimiento_train.jsonl\" -v \"formatted_tweets_sentimiento_valid.jsonl\" -m text-davinci-003"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "tfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
