{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c10ead33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from scipy.stats import chi2_contingency, kruskal\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "font = {'size'   : 45}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5675d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_head_tail(df, mode='retweet_count', head_perc=0.95, tail_perc=0.5):\n",
    "    \"\"\"\n",
    "    Given a dataframe `df` return the head and tail of the dataframe according to mode provided.\n",
    "    Args:\n",
    "        df (pd.DataFrame): Original dataframe\n",
    "        mode (Optional[str], optional): Metric to be used to get head/tail. Possible values: `retweet_follower_ratio,\n",
    "                                        retweets_in_relation_to_average, retweet_count`. Defaults to 'retweet_count'.\n",
    "        head_perc (Optional[float], optional): Percentile threshold to consider entries in head. Defaults to `0.95`.\n",
    "        tail_perc (Optional[float], optional): Percentile threshold to consider entries in tail. Defaults to `0.35`.\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.DataFrame]: head, tail of the dataframe\n",
    "    \"\"\"\n",
    "    top_threshold_retweets = df[mode].quantile(head_perc)\n",
    "    bot_threshold_retweets = df[mode].quantile(tail_perc)\n",
    "    idx_top_retweets = df[df[mode] >= top_threshold_retweets].index\n",
    "    idx_bot_retweets = df[df[mode] <= bot_threshold_retweets].index\n",
    "\n",
    "    head = df.loc[idx_top_retweets]\n",
    "    tail = df.loc[idx_bot_retweets]\n",
    "\n",
    "    return head, tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e0aa6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_in_relation_to_average(x) -> float:\n",
    "    \"\"\"\n",
    "    Support function to calculate the \"in_relation_to_average\" statistic. i.e How much a tweet\n",
    "    has been retweeted given the avg of the retweets of the user. E.g user's X retweet_count\n",
    "    average is 100. One of his tweets is retweeted 80 times then this tweets\n",
    "    \"in_relation_to_average\" score would be 80.\n",
    "    Args:\n",
    "        x (pd.Dataframe row): Row of a dataframe. Must contain \"retweet_count\", \"avg_retweets\"\n",
    "                              columns.\n",
    "    Returns:\n",
    "        (float): The \"in_relation_to_average\" statistic.\n",
    "    \"\"\"\n",
    "    if x['avg_retweets'] > 0:\n",
    "        return (100 * x['retweet_count']) / x['avg_retweets']\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a910708",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, ','.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m file_names:\n\u001b[1;32m----> 6\u001b[0m     temp \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     df\u001b[38;5;241m.\u001b[39mappend(temp)\n\u001b[0;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(df)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfm\\lib\\site-packages\\pandas\\io\\pickle.py:208\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;66;03m# We want to silence any warnings about, e.g. moved modules.\u001b[39;00m\n\u001b[0;32m    207\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mWarning\u001b[39;00m)\n\u001b[1;32m--> 208\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pc\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: invalid load key, ','."
     ]
    }
   ],
   "source": [
    "input_path = './data/main/*.pkl'\n",
    "file_names = glob.glob(input_path)\n",
    "\n",
    "df = []\n",
    "for f in file_names:\n",
    "    temp = pd.read_pickle(f)\n",
    "    df.append(temp)\n",
    "    \n",
    "df = pd.concat(df)\n",
    "\n",
    "# create month column\n",
    "df['created_at'] = pd.to_datetime(df['created_at'],utc=True)\n",
    "df['month'] = df['created_at'].dt.strftime('%m')\n",
    "df['month'] = df['month'].astype(int)\n",
    "\n",
    "# ignore entries with no tokens (most of them only @handles or urls)\n",
    "before = len(df)\n",
    "df = df[df.tokens.str.len() > 0]\n",
    "df = df.reset_index()\n",
    "after = len(df)\n",
    "print(f\"Ignoring {before - after} tweets with no content (handles/urls)\\n\")\n",
    "\n",
    "# ignore doublications \n",
    "df = df.drop_duplicates(subset='id')\n",
    "print(f\"Ignoring {after - len(df)} duplicate tweets \\n\")\n",
    "\n",
    "countries =  ['uk', 'wales', 'scotland', 'nireland', 'es', 'gr', 'catalan', 'basque']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ca69719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/cardiffnlp/xlm-twitter-politics-sentiment\"\n",
    "headers = {\"Authorization\": f\"Bearer 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\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": \"I like you. I love you\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bb5aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2d427d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "tfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
